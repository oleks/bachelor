\chapter{\mono{D}}

For the purposes of describing size-change termination we'll consider a language
\mono{D}. The following chapter describes the syntax and semantics of the
language.

\section{General properties}

The intent of the language is for it be used to explain concepts such as
size-change termination. One of the fundamental concepts required of the
language of application is that it's datatypes are well-founded. That is, any
subset $S$ of the range of values of some well-defined type has a value $s$
s.t. $\forall {s'\in S}\ s\leq s'$. This makes it ideal to chose some
oversimplistic data type structure rather than an army of basic types. Besides,
an apropriately defined basic data type should be able to represent arbitrarily
complex data values.

The language is initially first-order since the size-change termination
principle is first described for first-order programs later on in this work.
However, the language is designed so that it is easy to turn it into a
high-level language without much effort. This may prove necessary as we try to
expand size-change termination to higher-order programs.

The language is a call-by-value and purely functional to avoid any problems
that could arise from regarding lazy programs or where the notion of a global
state of the machine is relevant. Simply put, this is done to ensure elegance
of further proof with the help of the language.

\section{Data}

The language \mono{D} is untyped, and represents all data in terms of
\emph{unlabeled ordered binary trees}. Such a tree is recursively defined as
follows:

\begin{definition}

A set of nodes which is either the empty set, or a singleton set. A node has no
label, but has two binary trees as it's left and right child, respectively.

\end{definition}

To operate on such trees we require only the following capabilities:

\begin{itemize}

\item Represent a leaf node, that is, an empty set.

\item Construct binary nodes from two other trees.

\item Destruct binary nodes into their respective children.

\item Distinguish between leaves and nodes.

\end{itemize}

\subsection{Size}

For our purposes we'd also need to define the notion of size, and be sure to do
it in such a way that the data values that can be constructed are well-founded.

We know that the relation $<$ on the $\mathbb{N}$ is well-founded, so if we can
map \mono{D}'s values to $\mathbb{N}$, then we are well off.

\begin{definition}

Size of a value in \mono{D} is the number of nodes in the tree representing
that value.

\end{definition}

This definition almost allows us to devise an algorithm to compare the sizes of
data values. The problem withstanding is that two different values can have
rather diverging tree representations. Hence, comparaing them, using only the
operations defined for data values above, is seemingly impossible unless we
intially, or along the way, transform the trees of the values being compared
into some standard representation. We'll define this representaiton as follows:

\begin{definition}

The standard representation of a data value is the tree that only has leafs as
the left children of it's respective nodes.

\end{definition}

Hence, we'll define the function $\proc{Less}(A,B)$ with the help of an
auxiliary function $\proc{Normalize}(A)$ that \emph{normalizes} the given value
to the standard value representation.

Before we can define the conrete algorithms for the respective functions, we
need to formally define a few basic data representation and functions assumed
to be implemented beneath the language:

\begin{itemize}

\item $leaf$, represents a leaf node.

\item $\proc{Destruct}(A)\leadsto \{A_{left}, A_{right}\}$, destructs a node
into it's corresponding children.

\item $\proc{Construct}(A_{left},A_{right})\leadsto A$, constructs a node from
two binary trees, such that the trees become the nodes children.

\item $\proc{IsNode}(A)$, returns either $true$ or $false$, all depending on
whether $A$ is a node or a leaf, respectively.

\item $\proc{IsLeaf}(A)$, is the negation of $\proc{IsNode}(A)$.

\end{itemize}

We'll define the procedure $\proc{Normalize}(A)$ a little later, and start with
the procedure $\proc{Less}(A,B)$ to complete the overview of the function.
Before we can do that though, we need to define one additional peace of
notation:

\begin{itemize}

\item $leaf$ represents $false$

\item Any node represents $true$

\end{itemize}


returns a $leaf$ or a node consisting of two $leaf$s.

\begin{codebox}
\Procname{$\proc{Less}(A,B)$}
\li \If $\proc{IsLeaf}(A)$ \Then
\li   \Return $\proc{Construct}(leaf,leaf)$
    \End
\li \If $\proc{IsLeaf}(B)$ \Then
\li   \Return $leaf$
    \End
\zi
\li $A\gets \proc{Normalize}(A)$
\li $B\gets \proc{Normalize}(B)$
\zi
\li $\{\_, A_{right}\} \gets \proc{Destruct}(A)$
\li $\{\_, B_{right}\} \gets \proc{Destruct}(B)$
\zi
\li \Return $\proc{Less}(A_{right},B_{right})$
\end{codebox}

\begin{codebox}
\Procname{$\proc{Normalize}(A)$}
\li $\proc{NormalizeAuxiliary}(A,leaf,leaf)$
\end{codebox}

\begin{codebox}
\Procname{$\proc{NormalizeAuxiliary}(A,A',A_{normalized})$}
\li \If $\proc{IsNode}(A)$ \Then
\li   $A_{normalized}\gets \proc{Construct}(leaf,A_{normalized})$
\li \Else
\li   \Return $leaf$
    \End
\zi
\li $\{A_{left}, A_{right}\} \gets \proc{Destruct}(A)$
\li \If $\proc{IsNode}(A_{left})$ \Then
\li   $A'\gets \proc{Construct}(A_{left}, A')$
    \End
\li \If $\proc{IsNode}(A_{right})$ \Then
\li   $A \gets A_{right}$
\li \Else
\li   \If $\proc{IsNode}(A')$ \Then
\li     $\{A,A'\} \gets \proc{Destruct}(A')$
\li   \Else
\li     \Return $A_{normalized}$
      \End
    \End
\li \Return $\proc{Normalize}(A,A',A_{normalized})$
\end{codebox}

\begin{codebox}
\Procname{$\proc{Less}(A,B)$}
\li \If $\proc{IsLeaf}(A)$ \Then
\li   \Return $B$
    \End
\li \If $\proc{IsLeaf}(B)$ \Then
\li   \Return $leaf$
    \End
\zi
\li $A\gets \proc{Normalize}(A)$
\li $B\gets \proc{Normalize}(B)$
\zi
\li $\{\_, A_{right}\} \gets \proc{Destruct}(A)$
\li $\{\_, B_{right}\} \gets \proc{Destruct}(B)$
\zi
\li \Return $\proc{Less}(A_{right},B_{right})$
\end{codebox}

\section{The syntax}

The syntax is described in terms of an extended Backus-Naur form\footnotemark.
It is described in the simplest possible terms, that is, extraneous syntactical
sugar and basic terms are left out of the core language definition.  Instead,
these are defined ``as needed'', later on.

\footnotetext{The extension lends some constructs from regular expressions to
achieve a more concise dialect. The extension is described in further detail in
Appendix \ref{appendix:ebnf}.}

\subsection{Data \& Functions}

\mono{D} represents an empty tree with the atom \mono{0}. Node constrution is
done with the right-associative infix binary operator $\term{.}$, within
expressions. Node destruction is done with the exact same operator, except that
it is done while pattern matching an argument list to a parameter list of a
function declaration. Conventional braces can be used to override the
right-associativity of the $\term{.}$ operator in both cases.

Hence, the grammar for expressions and function declarations is defined as
follows:

\begin{align}
\nonterm{expression}\ ::=&\ \nonterm{value}\ (\ \term{.}\ \nonterm{expression}
\ )\ ?\\
\nonterm{value}\ ::=&\ \term{0}\ |\ \term{(}\ \nonterm{braces}\ \term{)}\ |
\ \nonterm{variable-name}\\
\nonterm{braces}\ ::=&\ \nonterm{expression}\ |
\ \nonterm{application}\\
\nonterm{application}\ ::=&\ \nonterm{function-name}
\ \nonterm{expression}^+\\
\nonterm{function}\ ::=&\ \nonterm{function-name}\ \nonterm{pattern}^+
\ \term{:=}\ \nonterm{expression}\\
\nonterm{pattern}\ ::=&\ \nonterm{pattern-value}\ (\ \term{.}
\ \nonterm{pattern}\ )\ ?\\
\nonterm{pattern-value}\ ::=&\ \term{0}\ |\ \term{\_}\ |\ \term{(}
\ \nonterm{pattern}\ \term{)}\ |\ \nonterm{variable-name}
\end{align}

The term $\term{\_}$ in $\nonterm{pattern-value}$ is the conventional wildcard
operator -- it indicates a value that is irrelevant to the function declaration
as such, but allows to keep the same function signature. Multiple wildcards in
the parameter list indicate possibly different value arguments, while multiple
occurances of the same variable name in the parameter list are disallowed.

It is worth noting that the sets $\nonterm{function-name}$ and
$\nonterm{variable-name}$ are disjoint, but are otherwise both defined by the
nonterminal $\nonterm{name}$:

\begin{align}
\nonterm{name}\ ::=&\ [\term{a}\mathmono{-}\term{z}]
\ \left (\ [\term{-}\ \term{a}\mathmono{-}\term{z}]^*
\ [\term{a}\mathmono{-}\term{z}]\ \right )?
\end{align}

\subsection{Size}

Althought the language is already complete, it would prove useful for further
analysis to define the notion of \emph{size}, and hence the equality and order
of relations on data values. Without further a-do, we define the size of a
value to be \emph{the number of nodes in the binary tree}.

The euqality and order relations are a bit more complicated though, as that
there is seemingly no \emph{elegant} way to decide whether one arbitrary binary
tree has the same or ..

Hence, the tree \mono{0} has the value $0$, the tree \mono{0.0} has the value
$1$, and the tree \mono{0.0.0} has the value $2$ as does it's symmetrical
equivalent, \mono{(0.0).0}.

This allows us to define the, otherwise built-in, function \mono{less} in a
primitive recursive fashion as follows:

\begin{verbatim}
less 0 0 = 0
less _._ 0 = 0
less 0 _._ = 0.0
less A.B X.Y = 

less AR.AL BR.BL = or (and (less AR BR) (less AL BL))
\end{verbatim}

This definition indicates that we choose for the empty tree to represent the
value \emph{false}, and for the tree \mono{0.0} to represent the value
\emph{true}. We'll keep the definition even more generic, and let the
\emph{nonempty} tree represent the value \emph{true}, as shall become useful
when we define the higher-order function \mono{if}
(\referToSection{language-higher-order-built-ins}).

Since the values begin at $0$ and grow at the rate of $1$ ... we can define it
as syntactic sugar and use nonnegative integers where ...

In addition to defining the actual data type we need to specify how we're going
to reason about it. Specifically, the questions of equality and order of values
constructed in this manner have to be answered.

For all intents and purposes, we can let the \emph{absolute value} of such a
tree-structured value be equal to $n-1$, where $n$ is the number of leafs in
the tree. Hence, the tree \mono{0} denotes $0$, \mono{0.0} denotes 1,
\mono{0.0.0} denotes 2 and so on.

The choice of this data representation yields the following properties for the
construction and destruction operators:

\begin{lemma} Construction of value yields a value strictly greater than either
of it's constituents. Specifically, the absolute value of the new value is the
sum of the absolute values of the constituents.\end{lemma}

\begin{lemma} Destruction of a value yields a pair of values who's absolute
values are strictly less than the absolute value of the original
value.\end{lemma}

\subsection{Programs}

Programs are defined in a conventional functional context and without mutual
recursion, namely:

\begin{align}
\nonterm{program}\ ::=&\ \nonterm{function}^*\ \nonterm{expression}
\end{align}

The order of the function definitions does matter wrt. pattern matching in so
far as those defined before are attempted first, if the match fails, the next
function with the same signature\footnote{In this case comprising of the name
of the function and it's arity.} is attempted.

Note, that we let the number of function definitions be zero as an
$\nonterm{expression}$ is a valid program as well. More generally, the program
can be thought of as a constant function, where the actual
$\nonterm{expression}$ simply has access to some predefined functions defined
by the function definitions in the program.

\subsection{Built-in high-order
functions}\label{section:language-higher-order-built-ins}

Although \mono{D} is initially a first-order language, we will ignore that
limitation for a bit and define a few higher-order functions to provide some
syntactical sugar to the language. Beyond the discussion in this section, these
higher-order functions should be regarded as \mono{D} built-ins.

\subsubsection{Branching}

In the following definition, the variable names \mono{true} and \mono{false}
refer to expressions to be executed in either case.

\begin{verbatim}
if 0 _ false := false
if _._ _ true := true
\end{verbatim}

As you can see, we employ the C convention that any value other than $0$ is a
``truthy'' value, and the expression \mono{true} is returned.

Although the call-by-value nature of the language does not allow for
short-circuiting the if-statements defined in such a way, this shouldn't be any
impediment to further analysis.

\subsection{Sample programs}

As an illustration of the language syntax, the following program reverses a tree:

\begin{verbatim}
reverse 0 := 0
reverse left.right := (reverse right).(reverse left)
\end{verbatim}

The following program computes the Fibonacci number \mono{n}:

\begin{verbatim}
fibonacci 0 x y := 0
fibonacci 0.0 x y := y
fibonacci n x y := fibonacci (minus n 0.0) y (add x y)
\end{verbatim}

\section{Semantics}

In the following section, the operational semantics of the language \mono{D}
are defined in terms of structured operaitonal semantics\cite{sos}.
\referToTable{sos-definitions} specifies most\footnote{The rest is discussed
further below and in \referToSection{language-semantics-memory}.} of the
syntactical elements used to define the semantic reduction rules below.

In addition to the notation specified in the table, we'll make use of
Haskell-like list comprehension when dealing with lists of elements. For
instance, $[e]$ refers to a list of expressions, and $[e'|e]$ refers to a list
of expressions that starts with the expression $e'$ and is followed by the list
of expressions, $e$. Also a bit alike Haskell, in both cases above, $e$ is used
as both a type and a variable.

\makeTable
{sos-definitions}
{Some of the syntactical elements used in the reduction rules for \mono{D}.}
{|lll|}
{\textbf{Notation}&\textbf{Description}}
{
$e$ & expression\\
$v$ & value\\
$n$ & variable name\\
$p$ & pattern\\
$0$ & the atom $0$\\
$\cdot$ & $\term{.}$\\
$\sigma$ & memory\\
$\sigma[n]$ & the value of variable $n$ in memory, returns some $v$
}

\subsection{Memory}\label{section:language-semantics-memory}

For the sake of an elegant notation, we'll define the notion of memory as a set
of stacks, one for each variable in the program. If a variable $n$ has an empty
stack, it is undefined, otherwise the value of the variable (in the present
scope) is the value at the top of the corresponding stack.

This model of memory allows us to deal with abitrary scope\footnote{Although
first-order \mono{D} can make little use of that.} in a rather elegant matter,
where we simply push a new value onto the corresponding stack when we enter a
nested scope and pop off the corresponding stacks when exiting a nested scope.
Hence, visiting a nested scope has the following operational semantics wrt.
$\sigma$:

$$\sigma\longrightarrow\sigma(n)\leftarrow v\longrightarrow\sigma$$

Following the conventions of structured operational semantics, the value of an
element, such as $\sigma$, does not change throughout a reduction rule. So in
the above example, the starting $\sigma$ is equivalent to the final $\sigma$.

\subsection{Evaluation}

\mono{D} has only one operator, namely $\term{.}$, which is a right-associative
binary operator, hence expressions are evaluated using the following triplet of
rules:

\begin{equation}
{
\left\langle e',\ \sigma\right\rangle
\longrightarrow
\left\langle e'',\ \sigma\right\rangle
}\over {
\left\langle e \cdot e',\ \sigma\right\rangle
\longrightarrow
\left\langle e \cdot e'',\ \sigma\right\rangle
}
\end{equation}

\begin{equation}
{
\left\langle e,\ \sigma\right\rangle
\longrightarrow
\left\langle e',\ \sigma\right\rangle
}\over {
\left\langle e\cdot v,\ \sigma\right\rangle
\longrightarrow
\left\langle e' \cdot v,\ \sigma\right\rangle
}
\end{equation}

\begin{equation}
\left\langle v \cdot v',\ \sigma\right\rangle
\longrightarrow
\left\langle v'',\ \sigma\right\rangle
\ \ \ \ \ \ (\text{where}\ v'' = v \cdot v')
\end{equation}

\subsubsection{Variables}

As expressions may contain variable names, we need a way to retrieve the values
of variables from memory:

\begin{equation}
\left\langle n,\ \sigma\right\rangle
\longrightarrow
\left\langle \sigma[n],\ \sigma\right\rangle
\end{equation}

\subsubsection{Application}

Function application is left-associative and has variable (constant at run
time) arity of at least one. The arity of the application depends on the
declaration that the function specifier, $f$, points to. Hence, we begin by
evaluating the function specifier itself to some expression $\lambda$ and a
pattern list $[p]$, that is, it's corresponding function declaration:

\begin{equation}
{
\left\langle f,\ \sigma\right\rangle
\longrightarrow
\left\langle \left\langle \lambda,\ [p]\right\rangle,\ \sigma\right\rangle
}\over{
\left\langle \left\langle f,\ [e]\right\rangle,\ \sigma\right\rangle
\longrightarrow
\left\langle
\left\langle\left\langle \lambda,\ [p]\right\rangle,\ [e]\right\rangle
,\ \sigma\right\rangle
}
\end{equation}

\emph{Note, in a first-order context $\lambda$ bares no special meaning,
however, the letter is carefully chosen to aid further extension of \mono{D} to
it's higher-order sibling.}

Followed by evaluation of the pattern and expression lists:

\begin{equation}
{
\left\langle p',\ \sigma\right\rangle
\longrightarrow
\left\langle p'',\ \sigma\right\rangle
\wedge
\left\langle e',\ \sigma\right\rangle
\longrightarrow
\left\langle e'',\ \sigma\right\rangle
}\over{
\left\langle p\cdot p',\ e\cdot e',\ \sigma\right\rangle
\longrightarrow
\left\langle p\cdot p'',\ e\cdot e'',\ \sigma\right\rangle
}
\end{equation}

\begin{equation}
{
\left\langle e',\ \sigma\right\rangle
\longrightarrow^*
\left\langle 0,\ \sigma\right\rangle
}\over{
\left\langle p\cdot 0,\ e\cdot e',\ \sigma\right\rangle
\longrightarrow
\left\langle p,\ e,\ \sigma\right\rangle
}
\end{equation}

\begin{equation}
{
\left\langle e',\ \sigma\right\rangle
\longrightarrow^*
\left\langle v',\ \sigma\right\rangle
}\over{
\left\langle p\cdot n,\ e\cdot e',\ \sigma\right\rangle
\longrightarrow
\left\langle p,\ e,\ \sigma(n)\leftarrow v' \right\rangle
}
\end{equation}

%\begin{equation}
%{
%\left\langle p',\ \sigma\right\rangle
%\longrightarrow
%\left\langle p'',\ \sigma\right\rangle
%\wedge
%\left\langle e',\ \sigma\right\rangle
%\longrightarrow
%\left\langle e'',\ \sigma\right\rangle
%}\over{
%\left\langle p'\cdot n,\ e'\cdot n,\ \sigma\right\rangle
%\longrightarrow
%\left\langle p''\cdot n,\ e''\cdot n,\ \sigma(n)\leftarrow v' \right\rangle
%}
%\end{equation}



We complete application by evaluating $\lambda$ with the new memory state:

\begin{equation}
\left\langle \lambda,\ \sigma([n])\leftarrow[v]\right\rangle
\longrightarrow
\left\langle v',\ \sigma\right\rangle
\end{equation}

\emph{Note, we return to the original $\sigma$ once $\lambda$ is evaluated.}

\newpage

This is small-step..

\begin{equation}
{
\left\langle n_f, [e], \sigma\right\rangle
\longrightarrow
\left\langle e_f, [p], [e], \sigma\right\rangle
\ \ \ \ \ \text{where}\ \left\langle e_f, [p] \right\rangle
\ \text{is the definition of the function with the name}\ n_f\text{.}
\over
\left\langle n_f, [e], \sigma\right\rangle
\longrightarrow
\left\langle v, \sigma\right\rangle
}
\end{equation}
